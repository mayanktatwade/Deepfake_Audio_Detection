{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "631733aa-42ba-4ab1-be50-1b4e557527c4",
   "metadata": {},
   "source": [
    "# Classification between real and deepfake audio\n",
    "### We are using FoR-2sec dataset for training and testing \n",
    "#### Loading the Data:\n",
    "- Load the dataset given in the repository\n",
    "- Convert the audio files to respective MFCC to further use in models as an array form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8bbbc9f-d73e-41af-a341-31df0d9eac3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (13956, 101, 13)\n",
      "y shape: (13956,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Set dataset path\n",
    "dataset_path = r\"E:\\for-2sec\\for-2seconds\\training\" # Here You must change the path to wherever you saved the datafile\n",
    "\n",
    "# Define MFCC parameters\n",
    "n_mfcc = 13\n",
    "sample_rate = 16000\n",
    "hop_length = 320  # Adjusted for 2 sec audio\n",
    "n_fft = 1024  # Typical FFT window size\n",
    "\n",
    "# Prepare storage lists\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Class mapping\n",
    "label_map = {\"real\": 0, \"fake\": 1}\n",
    "\n",
    "# Load MFCCs from dataset\n",
    "for label in [\"real\", \"fake\"]:\n",
    "    folder_path = os.path.join(dataset_path, label)\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Load audio file\n",
    "        y_audio, sr = librosa.load(file_path, sr=sample_rate)\n",
    "\n",
    "        # Extract MFCC with controlled hop length\n",
    "        mfccs = librosa.feature.mfcc(y=y_audio, sr=sr, n_mfcc=n_mfcc, hop_length=hop_length, n_fft=n_fft)\n",
    "        mfccs = mfccs.T  # Shape: (time_steps, n_mfcc)\n",
    "\n",
    "        # Append to dataset lists\n",
    "        X.append(mfccs)\n",
    "        y.append(label_map[label])\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X = np.array(X)  # Shape: (num_samples, 100, 13)\n",
    "y = np.array(y)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Shuffle dataset (X = MFCC features, y = Labels)\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "# Save to disk\n",
    "# np.save(\"mfcc_features.npy\", X)\n",
    "# np.save(\"labels.npy\", y)\n",
    "\n",
    "# Print shapes\n",
    "print(f\"X shape: {X.shape}\")  # Expected: (num_samples, 100, 13)\n",
    "print(f\"y shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16c8406-a374-4ca6-9ffd-ff47ca841bac",
   "metadata": {},
   "source": [
    "### Model 1: CNN + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85ea0ec4-a46d-492b-97c0-a9980e6c8231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (11164, 101, 13), Labels: (11164,)\n",
      "Testing data shape: (2792, 101, 13), Labels: (2792,)\n",
      "Epoch 1/20\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.7003 - loss: 0.5568\n",
      "Epoch 2/20\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.9184 - loss: 0.2297\n",
      "Epoch 3/20\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.9427 - loss: 0.1612\n",
      "Epoch 4/20\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.9611 - loss: 0.1059\n",
      "Epoch 5/20\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - accuracy: 0.9776 - loss: 0.0710\n",
      "Epoch 6/20\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.9755 - loss: 0.0760\n",
      "Epoch 7/20\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.9849 - loss: 0.0434\n",
      "Epoch 8/20\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.9899 - loss: 0.0319\n",
      "Epoch 9/20\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.9909 - loss: 0.0301\n",
      "Epoch 10/20\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - accuracy: 0.9910 - loss: 0.0308\n",
      "Epoch 11/20\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.9879 - loss: 0.0321\n",
      "Epoch 12/20\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.9927 - loss: 0.0209\n",
      "Epoch 13/20\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.9916 - loss: 0.0227\n",
      "Epoch 14/20\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.9945 - loss: 0.0185\n",
      "Epoch 15/20\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.9953 - loss: 0.0159\n",
      "Epoch 16/20\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.9950 - loss: 0.0210\n",
      "Epoch 17/20\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.9887 - loss: 0.0369\n",
      "Epoch 18/20\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.9931 - loss: 0.0215\n",
      "Epoch 19/20\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.9937 - loss: 0.0178\n",
      "Epoch 20/20\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.9943 - loss: 0.0182\n",
      "Training done successfully\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9944 - loss: 0.0186\n",
      "Test Loss: 0.0294\n",
      "Test Accuracy: 99.2837%\n",
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv1D(64, kernel_size=3, activation='relu', input_shape=(X.shape[1], X.shape[2])),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    LSTM(64),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into training (80%) and testing (20%) sets\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data shape: {X_train1.shape}, Labels: {y_train1.shape}\")\n",
    "print(f\"Testing data shape: {X_test1.shape}, Labels: {y_test1.shape}\")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train1, y_train1, epochs=20, batch_size=32)\n",
    "print('Training done successfully')\n",
    "\n",
    "# Evaluate on test data\n",
    "loss, accuracy = model.evaluate(X_test1, y_test1)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4%}\")\n",
    "\n",
    "model.save(\"deepfake_audio_detector_v3.keras\")\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d0ed2f-5b72-4a57-9602-f57dba3d7d3a",
   "metadata": {},
   "source": [
    "### Model 2: QSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2318d0f2-62f8-4e2d-8c85-10d22ee1cae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.41404011461319 %\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82      1396\n",
      "           1       0.80      0.86      0.83      1396\n",
      "\n",
      "    accuracy                           0.82      2792\n",
      "   macro avg       0.83      0.82      0.82      2792\n",
      "weighted avg       0.83      0.82      0.82      2792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_flat = X.reshape(X.shape[0], -1)  # (samples, time_steps * n_mfcc)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_flat)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    X_flat, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create QSVM with polynomial kernel of degree 2 (quadratic)\n",
    "qsvm = SVC(kernel='poly', degree=2)\n",
    "\n",
    "# Train\n",
    "qsvm.fit(X_train2, y_train2)\n",
    "\n",
    "# Predict\n",
    "y_pred2 = qsvm.predict(X_test2)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test2, y_pred2)*100,'%')\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737baeed-b515-4e0e-ae73-f1b96b9827df",
   "metadata": {},
   "source": [
    "### Model 3: Deepsonar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5c8a863-79e7-4056-a63c-afdb2a7f4d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mayank\\Python\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │             \u001b[38;5;34m320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m66,048\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m130\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93,250</span> (364.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m93,250\u001b[0m (364.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93,250</span> (364.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m93,250\u001b[0m (364.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.6812 - loss: 0.5729\n",
      "Epoch 2/10\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.8839 - loss: 0.2994\n",
      "Epoch 3/10\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.9055 - loss: 0.2432\n",
      "Epoch 4/10\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.9339 - loss: 0.1774\n",
      "Epoch 5/10\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.9401 - loss: 0.1623\n",
      "Epoch 6/10\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.9533 - loss: 0.1207\n",
      "Epoch 7/10\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.9629 - loss: 0.1008\n",
      "Epoch 8/10\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.9706 - loss: 0.0805\n",
      "Epoch 9/10\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.9811 - loss: 0.0603\n",
      "Epoch 10/10\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.9730 - loss: 0.0729\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9744 - loss: 0.0806\n",
      "\n",
      "✅ Test Accuracy: 97.64%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(np.unique(y))\n",
    "y3 = tf.keras.utils.to_categorical(y, num_classes)\n",
    "\n",
    "# Train-test split\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y3, test_size=0.2, random_state=42)\n",
    "\n",
    "# Expand dims to add channel for CNN: (samples, time_steps, n_mfcc, 1)\n",
    "X_train3 = X_train3[..., np.newaxis]\n",
    "X_test3 = X_test3[..., np.newaxis]\n",
    "\n",
    "# print(X_train.shape)\n",
    "\n",
    "\n",
    "# DeepSonar-Inspired Architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=X_train3.shape[1:]),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    tf.keras.layers.Reshape((-1, 64)),  # (time_steps/4, 64) to feed LSTM\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=False)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Train\n",
    "history = model.fit(X_train3, y_train3, epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate\n",
    "loss, acc = model.evaluate(X_test3, y_test3)\n",
    "print(f\"\\n✅ Test Accuracy: {acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8f7ec8-e379-4ee3-9274-e2f274499c69",
   "metadata": {},
   "source": [
    "### Bonus Model: CNN training with MFCC plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82abf472-18e1-44cf-9784-dbf2da390dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All MFCC images saved to: E:\\for-2sec\\images1\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "\n",
    "# Output folder to save plots\n",
    "output_dir = r\"E:\\for-2sec\\images1\"\n",
    "\n",
    "# Loop through all samples and save as images\n",
    "for i in range(len(X)):\n",
    "    mfcc = X[i].T  # Transpose for (n_mfcc, time_steps), suitable for plotting\n",
    "\n",
    "    # Create plot\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    librosa.display.specshow(mfcc, cmap=\"viridis\", x_axis='time')\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "    # Save figure\n",
    "    save_path = os.path.join(output_dir, f\"mfcc_{i}.png\")\n",
    "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "print(f\"All MFCC images saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94cbf94c-4c1e-42d5-829d-81f914b806ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 169ms/step - accuracy: 0.6236 - loss: 0.6689\n",
      "Epoch 2/5\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 160ms/step - accuracy: 0.7676 - loss: 0.5154\n",
      "Epoch 3/5\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 160ms/step - accuracy: 0.7935 - loss: 0.4653\n",
      "Epoch 4/5\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 161ms/step - accuracy: 0.8153 - loss: 0.4194\n",
      "Epoch 5/5\n",
      "\u001b[1m289/289\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 163ms/step - accuracy: 0.8344 - loss: 0.3851\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.8378 - loss: 0.3553\n",
      "Accuracy: 83.46320390701294 %\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Paths\n",
    "image_folder = r\"E:\\for-2sec\\images1\"\n",
    "# labels_path = \"labels.npy\"\n",
    "img_height, img_width = 128, 128\n",
    "\n",
    "# Load images\n",
    "X4 = []\n",
    "for i in range(11547):\n",
    "    img_path = os.path.join(image_folder, f\"mfcc_{i}.png\")\n",
    "    img = load_img(img_path, target_size=(img_height, img_width))\n",
    "    img_array = img_to_array(img) / 255.0  # Normalize\n",
    "    X4.append(img_array)\n",
    "\n",
    "X4 = np.array(X4)\n",
    "\n",
    "# Load labels\n",
    "y4 = y [:len(X4)] #Was facing an error for different sizes of X4 and y4\n",
    "num_classes = len(np.unique(y4))\n",
    "\n",
    "\n",
    "# One-hot encode after shuffling\n",
    "y4 = tf.keras.utils.to_categorical(y4, num_classes)\n",
    "\n",
    "# Split into training and testing\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(X4, y4, test_size=0.2, random_state=42)\n",
    "\n",
    "# CNN Model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(img_height, img_width, 3)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "history = model.fit(X_train4, y_train4, epochs=5, batch_size=32)\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_accuracy = model.evaluate(X_test4, y_test4)\n",
    "print(\"Accuracy:\", test_accuracy*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8838e0-3055-4e48-a59a-fafe5b8b7c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
